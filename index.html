<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Prajval Kumar Murali</title>
    <meta name="author" content="Prajval Murali">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <meta name="google-site-verification" content="ZvkJKAtKTqWNzI9OJ-WDKIc9MSRyhPTvACMnStdR9aE"/>
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Prajval Kumar Murali</name>
                        </p>

                        <p> I am currently employed as a Research Scientist in corporate research at the <a href="https://www.zeiss.de/corporate/home.html"> Zeiss Group </a> and building multi-modal robotic perception technologies since 2024.</p>
                        <p> Previously, since 2020 I worked at the <a href="https://www.bmwgroup.com/en.html"> BMW Group </a> Research towards developing novel algorithms for active multi-modal sensing and perception for autonomous intelligent robots. Herein, I worked towards my doctoral dissertation (Ph.D.) affiliated with
                            the <a href="https://www.gla.ac.uk/"> University of Glasgow</a>. I defended my Ph.D. thesis successfully in Dec 2024.
                        </p>

                        <p>
                            I have also worked as a robotics engineer at the <a href="https://iit.it/">Italian Institute of
                            Technology</a> from 2018 to 2020.
                            Here, I worked in a joint lab with <a href="https://www.dca.it/en/">Danieli Automation</a>
                            towards robotization of a safety-critical task in the steel industry. 
                        </p>
                        <p>
                            I obtained my Master of Science (M.S.) degree with highest distinction in the <a
                                href="https://master-emaro.ec-nantes.fr/">European Masters on Advanced Robotics
                            (EMARO+)</a>, an Erasmus Mundus Master’s program at
                            <a href="https://www.ec-nantes.fr/">Ecole Centrale de Nantes</a>, France and <a
                                href="https://unige.it/it/">University of Genova</a>, Italy.
                            I worked on my M.S. thesis on human-robot collaboration in a manufacturing environment
                            at the <a href="https://www.schaeffler.com/fork/">Schaeffler Group</a>.
                            I have been awarded the prestigious Erasmus Mundus Consortium Scholarship by the European
                            Union for my master's program.
                            I earned my bachelor's degree (B.Tech.) in engineering with highest distinctions from the <a
                                href="https://www.nitt.edu/">National Institute of Technology Tiruchirappalli</a>,
                            India.
                        <p>
                            <p>I have a strong background with C++/ Python, ROS and ML frameworks (Tensorflow/ PyTorch) and computer vision libraries (PCL, OpenCV).
  </p>
                            <strong> Expertise: </strong> Robotics / deep learning / multi-modal perception / point
                            cloud registration / 3D
                            reconstruction / robot-sensor calibration / 3D computer vision / tactile sensing


                        </p>
                        <strong> Disclaimer: </strong> This is my personal website and opinions presented here are my
                        own and do not reflect the views of my employers.
                        <p>

                        </p>
                        <p style="text-align:center">
                            <a href="https://scholar.google.com/citations?user=8W7cVy4AAAAJ&hl=en">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/prajval-kumar-murali/">LinkedIn</a> &nbsp/&nbsp
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/profile-circle1.png"><img style="width:100%;max-width:100%" alt="profile photo"
                                                                  src="images/profile-circle1.png"
                                                                  class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- NEWS -->
<!--            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">-->
<!--                <tbody>-->
<!--                <tr>-->
<!--                    <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--                        <h2>News</h2>-->
<!--                        <p>-->
<!--                            <strong>[Feb, 2023]</strong> New paper on "GMCR: Graph-based Maximum Consensus Estimation-->
<!--                            for Point Cloud Registration" has been accepted to IEEE ICRA 2023 </a>-->
<!--                        </p>-->
<!--                        <p><strong>[July, 2022]</strong> Our paper wins best paper award at IEEE FLEPS 2022  </a>-->
<!--                        </p>-->
<!--                    </td>-->
<!--                </tr>-->
<!--                </tbody>-->
<!--            </table>-->

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Awards</h2>
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- AWARDs -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:50%;vertical-align:middle">
                        <img style="max-height:200px;max-width:500px" src="images/best-paper-award-new.png" class="center">
                    </td>
                    <td style="padding:20px;width:50%;vertical-align:middle">
                        <!-- Add the second image here -->
                        <img style="max-height:200px;max-width:500px" src="images/ICRA_award.png" class="center">
                    </td>
                </tr>
                </tbody>
            </table>




            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Active Multi-Modal Pose Estimation</h2>
                    </td>
                </tr>
                </tbody>
            </table>



            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr onmouseout="font_stop()" onmouseover="font_start()">

                                        <!-- IJRR -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/ijrr.jpg"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>A Shared Visuo-Tactile Interactive Perception for Robust Object Pose Estimation
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong></u>, Bernd Porr, Mohsen Kaboli
                        <br>
                        <em>International Journal of Robotics Research (IJRR)</em>
                        <br>
                        <a href="https://journals.sagepub.com/doi/abs/10.1177/02783649241301443">[paper]</a><a
                            href="https://journals.sagepub.com/doi/abs/10.1177/02783649241301443#supplementary-materials">[video]</a>
                    </td>
                </tr>


                    <!-- ICRA-RA-L 2022 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/ral-icra.gif"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>Active Visuo-Tactile Interactive Robotic Perception for Accurate Object Pose
                            Estimation in Dense Clutter
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong></u>, Anirvan Dutta, Michael Gentner, Etienne Burdet,
                        Ravinder Dahiya and Mohsen Kaboli
                        <br>
                        <em>IEEE Robotics and Automation Letters (IEEE RA-L)</em>
                        <br>
                        <a href="https://ieeexplore.ieee.org/abstract/document/9709520">[paper]</a><a
                            href=" https://youtu.be/sjqWRFLL2Xw">[video]</a>
                    </td>
                </tr>

                <!-- IROS 2021 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/iros_website.gif"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>Active Visuo-Tactile Point Cloud Registration for Accurate Pose Estimation of
                            Objects in an Unknown Workspace
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong></u>, Michael Gentner, and Mohsen Kaboli
                        <br>
                        <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2021</em>
                        <br>
                        <a href="https://ieeexplore.ieee.org/document/9636877">[paper]</a> <a
                            href="https://youtu.be/Pu0Ghjlff7Q">[video]</a>
                    </td>
                </tr>

                <!-- FLEPS 2022 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/bunny_sim_final (1).png"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>An Empirical Evaluation of Various Information Gain Criteria for Active Tactile
                            Action Selection for Pose Estimation
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong></u>, Ravinder Dahiya and Mohsen Kaboli
                        <br>
                        <em>The IEEE Int. Conf on Flexible and Printable Sensors and Systems (FLEPS 2022)</em>
                        <br>
                        <a href="https://ieeexplore.ieee.org/document/9781598">[paper]</a>
                        <br>
                        <strong style="color:red;">Best Paper Award Winner</strong>
                    </td>
                </tr>

                <!-- ICRA 2023 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/icra_23.gif"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>GMCR: Graph-based Maximum Consensus Estimation for Point Cloud Registration
                        </papertitle>
                        <br>
                        Michael Gentner, <u><strong>Prajval Kumar Murali</strong></u>, and Mohsen Kaboli
                        <br>
                        <em>The IEEE International Conference on Robotics and Automation (ICRA 2023)</em>
                        <br>
                        <a href="https://arxiv.org/abs/2303.04032">[paper]</a>
                        <br>
                        <strong style="color:red;" href="https://www.icra2023.org/awards-finalists">Best Paper Award Finalist</strong>
                    </td>
                </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Active Multi-Modal Reconstruction</h2>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <!-- IROS 2023-->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/iros23.gif"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>Touch if it’s transparent! ACTOR: Active Tactile-based Category-Level Transparent Object Reconstruction
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong></u>, Bernd Porr and
                        Mohsen Kaboli
                        <br>
                        <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023</em>
                        <br>
                        <br>
                        <a href="https://arxiv.org/abs/2307.16254">[paper]</a>
                        <br>
                    </td>
                </tr>

            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Robust Cross-Modal Perception</h2>
                    </td>
                </tr>
                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <!-- IROS-RA-L 2022 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/ral_iros22.gif"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>Deep Active Cross-Modal Visuo-Tactile Transfer Learning for Robotic Object
                            Recognition
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong></u>, Cong Wang, Dongheui Lee, Ravinder Dahiya and
                        Mohsen Kaboli
                        <br>
                        <em>IEEE Robotics and Automation Letters (IEEE RA-L)</em>
                        <br>
                        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9830870">[paper]</a>
                    </td>
                </tr>


                <!-- FLEPS 2022 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/fig1.png"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>Towards Robust 3D Object Recognition with Dense-to-Sparse Deep Domain Adaptation
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong> </u>, Cong Wang, Ravinder Dahiya and Mohsen Kaboli
                        <br>
                        <em>The IEEE Int. Conf on Flexible and Printable Sensors and Systems (FLEPS 2022)</em>
                        <br>
                        <a href="https://ieeexplore.ieee.org/document/9781490">[paper]</a>
                    </td>
                </tr>

                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Human-Robot/ Human-Vehicle Collaboration</h2>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>


                <!-- AIS -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/figure1_new.png"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>Intelligent In-Vehicle Interaction Technologies</papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong> </u>, Mohsen Kaboli, and Ravinder Dahiya
                        <br>
                        <em>Advanced Intelligent Systems</em>
                        <br>
                        <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/aisy.202100122">[paper]</a>
                    </td>
                </tr>

                <!-- JIST 2020 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/jist.gif"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>Deployment and Evaluation of a Flexible Human-Robot Collaboration Model Based on
                            AND/OR Graphs in a Manufacturing Environment
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong></u>, Kourosh Darvish, Fulvio Mastrogiovanni
                        <br>
                        <em>Springer Journal of Intelligent Service Robotics (JIST)</em>
                        <br>
                        <a href="https://link.springer.com/article/10.1007/s11370-020-00332-9">[paper]</a><a
                            href="https://www.youtube.com/watch?v=mF22PPmwHN0&feature=youtu.be">[video]</a><a
                            href="https://github.com/EmaroLab/industrialRobot_task_planning">[code]</a>
                    </td>
                </tr>

                <!-- ETFA 2020 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/etfa_new.png"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>A Flexible Software Architecture for Robotic Industrial Applications</papertitle>
                        <br>
                        Angelo Rendiniello, Alberto Remus, Ines Sorrentino,<u><strong> Prajval Kumar
                        Murali </strong></u>, Daniele Pucci, Marco Maggiali, Lorenzo Natale, Enrico Villagrossi, Andrea
                        Polo, Alessandro Ardesi, Silvio Traversaro
                        <br>
                        <em>IEEE International Conference on Emerging Technologies and Factory Automation, ETFA
                            2020</em>
                        <br>
                        <a href="https://ieeexplore.ieee.org/abstract/document/9212095">[paper]</a>
                    </td>
                </tr>
                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Multi-Modal Sensor Calibration</h2>
                    </td>
                </tr>
                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <!-- ICRA 2021 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/icub.png"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>In Situ Translational Hand-Eye Calibration of Laser Profile Sensors using Arbitrary
                            Objects
                        </papertitle>
                        <br>
                        <u><strong>Prajval Kumar Murali</strong></u>, Ines Sorrentino, Angelo Rendiniello, Claudio
                        Fantacci, Enrico Villagrossi, Andrea Polo, Alessandro Ardesi, Marco Maggiali, Lorenzo Natale,
                        Daniele Pucci, Silvio Traversaro
                        <br>
                        <em>IEEE International Conference on Robotics and Automation, ICRA 2021</em>
                        <br>
                        <a href="https://ieeexplore.ieee.org/iel7/9560720/9560666/09561055.pdf">[paper]</a>
                    </td>
                </tr>

                <!-- IROS 2015 -->
                <tr onmouseout="font_stop()" onmouseover="font_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle"><img
                            style="max-height:180px;max-width:180px" src="images/iros.gif"></td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>Active calibration of tactile sensors mounted on a robotic hand</papertitle>
                        <br>
                        Benjamin Navarro, <u><strong>Prajval Kumar Murali </strong></u>, Aicha Fonte, Philippe Fraisse,
                        Gérard Poisson, Andrea Cherubini
                        <br>
                        <em>IEEE/RSJ Intelligent RObots and Systems IROS 2015, Workshop on Multimodal sensor-based robot
                            control for HRI and soft manipulation</em>
                        <br>
                        <a href="https://hal-lirmm.ccsd.cnrs.fr/lirmm-01247148/document">[paper]</a><a
                            href="https://www.youtube.com/watch?v=kJm6jaVxBlI">[video]</a>
                        <br>
                    </td>
                </tr>

                </tbody>
            </table>

            <!-- Courtesy -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <p style="text-align:right;font-size:small;">
                            Website by the courtesy of <a href="https://jonbarron.info/">Jon Barron</a>.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>


</html>
